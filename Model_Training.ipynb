{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка нужных версий библиотек"
      ],
      "metadata": {
        "id": "hbfDh6BBEn-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0\n",
        "!pip install torchvision==0.12.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeBJO1wT_GyL",
        "outputId": "68e307a6-fe6c-49ff-9163-1b9bda1f24ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.11.0\n",
            "  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0\n",
            "Collecting torchvision==0.12.0\n",
            "  Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (2.31.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (1.11.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl8sXXvh1nnS"
      },
      "outputs": [],
      "source": [
        "!pip install pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# Download Torch/Vision repo to use some files from\n",
        "# references/detection\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.8.2\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "metadata": {
        "id": "-v1yIB8D2okx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from engine import train_one_epoch, evaluate"
      ],
      "metadata": {
        "id": "PL6-mL5D1yl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем данные с гугл-диска.\n"
      ],
      "metadata": {
        "id": "8sTbpno7wdDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "id=\"/content/drive/MyDrive/hack1\""
      ],
      "metadata": {
        "id": "4L7p6fhD5E1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv_path = id+\"/data.csv\"\n",
        "\n",
        "train_images = id\n"
      ],
      "metadata": {
        "id": "c06Ss6yf12h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=pd.read_csv(train_csv_path)\n",
        "train_data"
      ],
      "metadata": {
        "id": "B9-CE0PrA4HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс C_Dataset нужен для обучения модели"
      ],
      "metadata": {
        "id": "GyDnBt5jFLSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from torchvision import transforms\n",
        "\n",
        "class C_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, image_path,**kwargs):\n",
        "        self.images_p = df[\"filename\"].to_numpy()\n",
        "        self.df = df.drop(columns=[\"filename\"])\n",
        "        self.image_path = image_path\n",
        "        self.targets=[]\n",
        "        self.images=[]\n",
        "        self.F = transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    ToTensorV2(p=1)\n",
        "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))#transforms.ToTensor()\n",
        "        self.transforms=transforms\n",
        "        for i in range(len(df)):\n",
        "          if(self.images_p[i][-4:]!=\".png\"):\n",
        "            self.images_p[i]=self.images_p[i]+\".png\"\n",
        "        df=df.drop(columns=[\"filename\"])\n",
        "        data=df.to_numpy()\n",
        "        for i in range(len(data)):\n",
        "          print(image_path+\"/\"+self.images_p[i])\n",
        "          img = cv2.imread(image_path+\"/\"+self.images_p[i])\n",
        "          w=0\n",
        "          h=0\n",
        "          h=len(img)\n",
        "          w=len(img[0])\n",
        "          l=0\n",
        "          for j in range(len(data[i])):\n",
        "            if not(np.isnan(data[i][j])):\n",
        "              l+=1\n",
        "          l//=5\n",
        "          xmins = []\n",
        "          ymins = []\n",
        "          xmaxs = []\n",
        "          ymaxs = []\n",
        "          labels=[]\n",
        "          count=0\n",
        "          for j in range(l):\n",
        "            count+=1\n",
        "            x_m=max(min(data[i][5*j+1], data[i][5*j+2+1]),0)\n",
        "            x_ma=min(max(data[i][5*j+1], data[i][5*j+2+1]), w)\n",
        "            y_m=max(min(data[i][5*j+2], data[i][5*j+4]),0)\n",
        "            y_ma=min(max(data[i][5*j+2], data[i][5*j+4]), h)\n",
        "            labels.append(int(data[i][5*j]))\n",
        "            xmins.append(x_m)\n",
        "            xmaxs.append(x_ma)\n",
        "            ymins.append(y_m)\n",
        "            ymaxs.append(y_ma)\n",
        "          for j in range(len(xmins)):\n",
        "            if xmins[j]<0:\n",
        "              xmins[j]=0\n",
        "            if ymins[j]<0:\n",
        "              ymins[j]=0\n",
        "          labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "          boxes = torch.as_tensor(np.stack([xmins, ymins, xmaxs, ymaxs], axis=1), dtype=torch.float32)\n",
        "          areas = (boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:,0])\n",
        "          areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "          image_id = torch.tensor([i])\n",
        "          iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
        "          target = {}\n",
        "          target[\"boxes\"] = boxes\n",
        "          target[\"labels\"] = labels\n",
        "          target[\"image_id\"] = image_id\n",
        "          target[\"area\"] = areas\n",
        "          target[\"iscrowd\"] = iscrowd\n",
        "          self.targets.append(target)\n",
        "          self.images.append(image_path+\"/\"+self.images_p[i])\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "              img=cv2.imread(self.images[idx])\n",
        "              img = self.F(image=img, bboxes=self.targets[idx][\"boxes\"], labels=self.targets[idx][\"labels\"])\n",
        "              return torch.as_tensor(img[\"image\"], dtype=torch.float32), self.targets[idx]\n",
        "    def get_height_and_width(self, image):\n",
        "        image_data = self.df.loc[self.df['filename'] == image]\n",
        "        return image_data[\"width\"].values[0], image_data[\"height\"].values[0]\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "EJAlecd_7VT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = C_Dataset(train_data, id)\n"
      ],
      "metadata": {
        "id": "zKUdem-f7i5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "kYSRzyN87pbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используем алгоритм Faster RCNN с опорной моделью ResNet50\n",
        "\n",
        "При этом модель распознаёт 4 класса пыли"
      ],
      "metadata": {
        "id": "7wTD-si-se-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detection_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "num_classes = 4\n",
        "in_features = detection_model.roi_heads.box_predictor.cls_score.in_features\n",
        "detection_model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)"
      ],
      "metadata": {
        "id": "NY_FQeJn8Cd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Указываем, что обучение модели будет происходить на GPU для экономии времени"
      ],
      "metadata": {
        "id": "ShzzldYHy2V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "detection_model.to(device)"
      ],
      "metadata": {
        "id": "rxNxo1f58V4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(model, train_loader, val_loader, epochs=10):\n",
        "    # construct an optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=0.00001, momentum=0.9, weight_decay=0.0005)\n",
        "    # and a learning rate scheduler\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                   step_size=3,\n",
        "                                                   gamma=0.1)\n",
        "    for epoch in range(epochs):\n",
        "        # train for one epoch, printing every 10 iterations\n",
        "        train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=1)\n",
        "        # update the learning rate\n",
        "        lr_scheduler.step()\n",
        "        # evaluate on the test dataset\n",
        "        #evaluate(model, val_loader, device=device)"
      ],
      "metadata": {
        "id": "Rexnt_MY8Zch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучаем модель и сохраням веса"
      ],
      "metadata": {
        "id": "eCqM80dKHGBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training(detection_model, data_loader_train,val_loader=data_loader_train, epochs=30)\n",
        "torch.save(detection_model.state_dict(), id+'/resnet1_50.pth')"
      ],
      "metadata": {
        "id": "ao-idYfS8aYw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}